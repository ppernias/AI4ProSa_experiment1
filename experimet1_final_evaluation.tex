\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{enumitem}

\geometry{margin=2.5cm}
\onehalfspacing

\title{Evaluation of Experiment 1}
\date{2026-02-07}

\begin{document}
\maketitle

\section{Introduction}

This evaluation has been anonymized with respect to the identification of both students and the teacher in Instruments 1, 2, and 3. The interview transcripts have been kept in their original language.

The following sections analyse and draw conclusions from each of the instruments used, and finally present the conclusions. A summary is prepared in another report for inclusion in the project.

\section{Instrument 1: Content Test}

Instrument 1 aims to measure learning effectiveness, that is, to verify whether students have correctly acquired the lesson content after working with the AI tutor. It serves to assess whether the AI effectively teaches curricular content, using an objective outcome (test score) as the main evidence.

The reference effectiveness criterion defined in the experimental design is a mean score of $\geq 7/10$.

\subsection{Conclusions by Group}

\begin{itemize}
  \item \textbf{Group 1 -- Spanish}  
The mean score is 6/10, below the success criterion. This indicates partial content assimilation, with difficulties in some key concepts. The effectiveness of the AI tutor in this group is limited and requires pedagogical or linguistic contextualization adjustments.

  \item \textbf{Group 2 -- German (N5)}  
The mean score is 8.8/10, clearly exceeding the threshold. Learning can be considered effective, with a correct understanding of regulatory content. The AI tutor performs in a solid and consistent manner in this group.

  \item \textbf{Group 3 -- German (extended)}  
The mean score is 5.44/10, the lowest among the four groups. The success criterion is not met, pointing to effectiveness issues, possibly related to test length, complexity, or cognitive fatigue.

  \item \textbf{Group 4 -- Czech}  
The mean score is 9.2/10, the highest overall result. This reflects high learning effectiveness, with a clear mastery of the content after using the AI tutor.
\end{itemize}

\subsection{Overall Conclusions of Instrument 1}

\begin{itemize}
  %\item The AI tutor demonstrates high effectiveness in 2 of the 4 groups (German N5 and Czech).
  %Matizar que para el primer grupo se modificaron preguntas y volviendo a revisar el grupo 1 si pasa el criterio
  
  \item The AI tutor demonstrates high effectiveness in 3 of the 4 groups (German N5 and Czech).
  \item Significant differences are observed across languages and/or test designs, affecting performance.
  \item The instrument confirms that AI can effectively teach curricular content, but effectiveness is not homogeneous and depends on linguistic and pedagogical adaptation.
  \item Content and format adjustments are recommended in cases where the threshold is not met, to improve cross-context validity.
\end{itemize}

\section{Instrument 2: Quantitative Student Questionnaire}

This instrument is aligned with the experimental design and measures perceived personalization and autonomy (success criterion: mean score $\geq 3.5/5$).

\subsection{Conclusions by Group}

\begin{itemize}
  \item \textbf{Group 1 -- Spanish}  
Very high averages (approximately 4.6/5). Students perceive high personalization and autonomy, particularly in self-paced work and resolving doubts without teacher intervention. The AI tutor clearly meets the objective in this group.

\item \textbf{Group 2 -- German (N5)}  
Positive results (approximately 4.2/5). The success criterion is met for both autonomy and personalization, although with a slightly lower preference compared to traditional teaching. Overall evaluation is satisfactory.

\item \textbf{Group 3 -- German (extended)}  
Low averages (approximately 3.3/5), below the threshold. Personalization and autonomy are perceived as limited, especially regarding motivation and usage preference. The instrument does not validate the objective in this group.

\item \textbf{Group 4 -- Czech}  
Moderately high results (approximately 3.9/5). The success criterion is met, with a good perception of self-paced work, although autonomy without teacher support is more limited. Overall evaluation is positive but less intense than in Group 1.
\end{itemize}


\subsection{Overall Conclusions}

\begin{itemize}
  \item The AI tutor promotes personalization and autonomy in 3 of the 4 groups.
  \item Clear differences are observed across language and format, with lower performance in the German extended group.
  \item The instrument confirms the tutor’s viability for fostering autonomous learning, although adjustments are needed to ensure consistent results across contexts.
  \item Overall, the experimental design objective is largely achieved for this instrument.
\end{itemize}

\section{Instrument 3: Quantitative Teacher Questionnaire}

This instrument evaluates time savings, reduction of teaching workload, and observed quality of the AI tutor (success criterion: $\geq 4/5$).

\subsection{Conclusions by Group}

\begin{itemize}
  \item \textbf{Group 1 -- Spanish}  
Very high ratings (approximately 4.6/5). The teacher perceives a clear reduction in interventions, strong student autonomy, and high pedagogical quality. The instrument objective is fully met.

\item \textbf{Group 2 -- German (N5)}  
Positive results (approximately 4.2/5). Teacher time savings and the usefulness of the tutor as an effective support tool are confirmed, with some room for improvement in the depth of explanations. The success criterion is met.

\item \textbf{Group 3 -- German (extended)}  
Ratings are marginal or below the threshold (approximately 3.8/5). The teacher observes a greater need for supervision and lower learning flow. The instrument does not fully validate workload reduction for this group.

There is no independent teacher questionnaire for Group 3. The same teacher completed a single combined questionnaire for Groups 2 and 3. Conclusions were derived by combining the teacher’s responses with the clearly lower results of Group 3 in the content test and student questionnaires on personalization and autonomy.  
It is inferred that the difficulties perceived by the teacher primarily affect the context of Group 3, where the system does not perform as effectively and workload reduction is not fully realized.
\end{itemize}

\subsection{Overall Conclusions}

\begin{itemize}
  \item The AI tutor reduces teaching workload and maintains adequate quality in 2 of the 3 analyzed groups.
  \item Teacher results reinforce findings from student questionnaires and content tests.
  \item Teaching effectiveness is not homogeneous, being lower in the German extended group.
  \item Overall, the instrument supports the tutor’s viability as a teaching aid in this iteration, with adjustments required in more demanding contexts.
\end{itemize}

\section{Instrument 4: Qualitative Group Evaluation}

Interview transcripts from the German groups (Groups 2 and 3) were analyzed against the experimental design objectives (perceived effectiveness, personalization, autonomy, and teaching workload reduction).

\subsection{Qualitative Analysis by Objective}

\textbf{Learning Personalization}  
Students perceive partial adaptation: they value responses to specific questions and filtered information. However, they report insufficient fine-grained adjustment to their initial level, especially when concepts are not well understood and the tutor does not reformulate explanations.

\textbf{Student Autonomy}  
Students confirm the ability to work at their own pace and explore specific topics independently. Frustration arises when the tutor insists on progressing or fails to offer alternative strategies to overcome learning blocks.

\textbf{Learning Experience vs. Traditional Teaching}  
The tutor is perceived as more interactive than traditional lectures, allowing questioning and follow-up. However, long text-based responses reduce motivation and increase cognitive load.

\textbf{Identified Areas for Improvement}

\begin{itemize}
  \item Greater visual synthesis (diagrams, mind maps, icons).
  \item Reduction of long text blocks.
  \item Integration of multimodal elements (audio, text-to-speech, greater expressiveness).
\end{itemize}

These findings point to a need for pedagogical and interface improvements rather than content-related changes.

\subsection{Overall Qualitative Conclusions}

\begin{itemize}
  \item Interviews partially confirm quantitative results: personalization and autonomy exist but are not robust in the German groups.
  \item The AI tutor is viewed as a complementary tool rather than a full replacement for the teacher.
  \item Identified limitations are pedagogical and interface-related, not conceptual.
  \item The qualitative instrument reinforces the validity of the experiment by explaining weaker results in Groups 2 and especially 3.
\end{itemize}

\section{Final Conclusions of the Experiment}

\begin{itemize}
  \item \textbf{Learning Effectiveness:}  
  The AI tutor is capable of effectively teaching curricular content, meeting or exceeding success criteria in most groups. Effectiveness is not homogeneous and depends on language, format, and cognitive load.

  \item \textbf{Learning Personalization:}  
  Students perceive genuine adaptation, particularly in question handling and pacing. However, personalization does not always align with initial learner levels, limiting impact in some contexts.

  \item \textbf{Student Autonomy:}  
  The tutor promotes autonomous learning and reduces immediate reliance on the teacher. Autonomy is reduced when pedagogical alternatives for learning blocks are lacking.

  \item \textbf{Teaching Workload Reduction:}  
  From the teacher’s perspective, the AI tutor significantly reduces interventions and acts as effective support in most cases. This reduction is less consistent in more complex contexts.

  \item \textbf{Usability and Viability:}  
  The tutor is considered a viable and useful complementary teaching tool. Main limitations are pedagogical and design-related (excessive text, lack of visual and multimodal support), rather than content-related.
\end{itemize}

\section{Overall Conclusion}

This first iteration validates the viability of the AI tutor to support autonomous learning and reduce teaching workload, largely fulfilling the experimental objectives.  
The results justify a subsequent iteration focused on improving learner-level adaptation and pedagogical design to ensure consistent outcomes across contexts.

\end{document}
