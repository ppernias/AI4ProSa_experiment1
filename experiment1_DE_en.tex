\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{graphicx}

\geometry{margin=2.5cm}
\onehalfspacing

\title{Experimental Validation of an Artificial Intelligence--Based Tutor for Autonomous Learning}
\author{AI4PROSA Project \\ University of Alicante}
\date{}

\begin{document}
\maketitle

\section{Introduction}

This report presents the results of a first experimental iteration aimed at validating an artificial intelligence--based tutor as a support tool for autonomous learning in higher education. The experiment is framed within the AI4PROSA project and focuses on Lesson 2 of the child product safety module, addressing the obligations of economic operators under European legislation.

The general objective of the study is to analyze whether an AI tutor can:
\begin{itemize}
    \item facilitate effective content acquisition,
    \item foster student autonomy,
    \item personalize the learning process,
    \item and reduce teacher workload during instructional sessions.
\end{itemize}

The experimental design combines quantitative and qualitative instruments following a mixed-methods approach, enabling triangulation of results.

\section{Experimental Design}

The experiment was conducted with a pilot group of five university students and one teacher-researcher. The session lasted a maximum of two hours and took place in a controlled laboratory environment.

\subsection{Evaluation Instruments}

Four evaluation instruments were defined and applied as part of the experimental design:

\begin{enumerate}
    \item Content knowledge test (learning effectiveness).
    \item Quantitative questionnaire for students (perceived personalization and autonomy).
    \item Quantitative questionnaire for the teacher (workload and observed quality).
    \item Post-experiment qualitative group interview.
\end{enumerate}

Preliminary success criteria were established for each evaluated dimension and used as reference points for result analysis.

\section{Results}

\subsection{Learning Effectiveness: Content Knowledge Test}

The content knowledge test assessed the acquisition of curricular knowledge addressed during the session. The predefined success criterion was a mean score equal to or greater than 7 out of 10.

All five participants completed the test. All reported very low or nonexistent prior knowledge of the topic before the intervention.

\begin{table}[h]
\centering
\begin{tabular}{cc}
\toprule
Student & Score (/10) \\
\midrule
S1 & 8 \\
S2 & 9 \\
S3 & 9 \\
S4 & 9 \\
S5 & 9 \\
\bottomrule
\end{tabular}
\caption{Results of the content knowledge test}
\end{table}

The mean score was 8.8 out of 10, clearly exceeding the predefined success criterion. These results indicate effective acquisition of the evaluated content.

The qualitative interview supports these findings, showing that students understood key concepts and the underlying regulatory logic rather than relying on rote memorization.

\subsection{Student Perceptions: Personalization and Autonomy}

The student questionnaire employed a 5-point Likert scale. The success criteria were defined as a mean score equal to or greater than 3.5 for both personalization and autonomy.

\subsubsection{Perceived Personalization}

Items related to personalization yielded generally positive evaluations, with an approximate mean of 4.1 out of 5. Students perceived that the tutor responded to their individual questions and allowed them to progress at different learning paces.

Qualitative data nuance these results, indicating that personalization is mainly reactive: the tutor responds appropriately to student queries but does not consistently provide proactive guidance when learners become unsure how to proceed.

\subsubsection{Learning Autonomy}

Autonomy was the highest-rated dimension. Students reported being able to resolve doubts without teacher assistance (5.0/5) and to learn independently using the tutor (4.8/5).

These results are reinforced by the qualitative interview, where participants highlighted the absence of pressure, freedom to ask repeated questions, and control over their learning pace.

\subsubsection{Preference and Future Use}

Preference compared to traditional instruction was moderate (3.6/5), whereas willingness to reuse the tutor for other course topics was clearly positive (4.0/5). Students conceptualized the tutor as a complement to the teacher rather than a replacement.

\subsection{Teacher Perspective: Workload and Viability}

The teacher questionnaire assessed workload reduction, observed pedagogical quality, and tutor viability.

During the session:
\begin{itemize}
    \item no academic interventions by the teacher were required,
    \item no student required individual instructional support.
\end{itemize}

These outcomes clearly meet the predefined success criteria. The teacher rated workload reduction as 4 out of 5.

Regarding pedagogical quality, the tutor's explanations were considered adequate but improvable (3/5), with occasional need for supplementation or correction.

Despite these limitations, the tutor was considered viable for regular use (4/5) and highly recommendable to other educators (5/5).

\section{Discussion}

The integration of quantitative and qualitative results reveals strong coherence across instruments. The AI tutor demonstrates high effectiveness in content acquisition, particularly for students with limited prior knowledge.

Student autonomy emerges as a key mediating factor supporting learning effectiveness and directly contributing to workload reduction. Perceived personalization is positive but constrained by the lack of proactive pedagogical scaffolding.

Both students and the teacher consistently identify areas for improvement, especially regarding explanation structure, visual support, and guidance when learners are unsure how to proceed.

These limitations do not undermine the validity of the findings; rather, they delineate the current scope of the system and provide clear directions for future iterations.

\section{Conclusions}

The results of this first experimental iteration indicate that the AI-based tutor:
\begin{itemize}
    \item enables effective acquisition of curricular content,
    \item fosters a high degree of student autonomy,
    \item significantly reduces teacher workload during instructional sessions,
    \item and is considered viable and recommendable from a professional perspective.
\end{itemize}

The tutor is validated as a learning support tool consistent with the proposed experimental design. The identified improvement areas provide a solid foundation for subsequent development and refinement.

\end{document}
